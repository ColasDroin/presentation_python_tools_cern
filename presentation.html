<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />

    <title>
      Python tools for the development, submission to clusters, and analysis of
      Dynamic Aperture studies
    </title>

    <meta
      name="description"
      content="Python tools for the development, submission to clusters, and analysis of Dynamic Aperture studies"
    />
    <meta name="author" content="Colas Droin" />

    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta
      name="apple-mobile-web-app-status-bar-style"
      content="black-translucent"
    />

    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <link rel="stylesheet" href="dist/reset.css" />
    <link rel="stylesheet" href="dist/reveal.css" />
    <link rel="stylesheet" href="dist/theme/moon.css" id="theme" />

    <!-- Theme used for syntax highlighting of code -->
    <link rel="stylesheet" href="plugin/highlight/monokai.css" />
  </head>

  <body>
    <div class="reveal">
      <!-- Any section element inside of this container is displayed as a slide -->
      <div class="slides">
        <section>
          <a href="https://revealjs.com">
            <img
              src="assets/logo_cern.svg"
              alt="reveal.js logo"
              style="
                height: 180px;
                margin: 0 auto 4rem auto;
                background: transparent;
              "
              class="demo-logo"
            />
          </a>
          <h6>
            Python tools for <span style="color: #00a5a5">D</span>ynamic
            <span style="color: #00a5a5">A</span>perture studies
          </h6>
          <p>
            <small>COLAS DROIN</small>
            <small> - 08.11.2024</small>
          </p>
        </section>

        <section data-markdown data-background="#eeeeee">
          <script type="text/template">
            ### Introduction
          </script>
        </section>

        <section data-markdown>
          <script type="text/template">
            ### <span style="color: #00a5a5">What</span> is a DA study?

            <small>

              Dynamic Aperture studies are used to <span style="color: #00a5a5;">optimize the beam lifetime</span> all along an accelerator cycle.

            <img src="assets/scenario.png" alt="scenario" width="600"/>

            It is known that parameters such as the tune, chromaticity, octupole intensities and
            many others can have a significant impact on the beam lifetime.

            </small>
          </script>
        </section>

        <section data-markdown>
          <script type="text/template">
            #### <span style="color: #00a5a5">DA</span> is a good proxy for <span style="color: #00a5a5">beam lifetime</span>

            <small>

              It has been shown in 2019, in MD studies, that the DA correlates with the beam lifetime.

            <img src="assets/correlation.png" alt="scenario" width="400"/>
            <img src="assets/correlation_2.png" alt="scenario" width="400"/>

            Therefore, the DA can be used to maximize the beam lifetime by optimizing the machine parameters.

            </small>
          </script>
        </section>

        <section data-markdown>
          <script type="text/template">
            ### <span style="color: #00a5a5">How</span> is the DA computed?

            <small>

            Several formulas are available to compute the DA (<span style="color: orange;">all debatable...</span>).

            We usually consider the <span style="color: #00a5a5">minimum DA</span>, i.e. the minimal amplitude of particles lost after tracking a sample distribution for a given number of turns.

            <img src="assets/DA_def.png" alt="DA-def" width="300"/>

            In practice, we consider <span style="color: #00a5a5">1280 particles</span> initially distributed according to <span style="color: #00a5a5">5 regular angles on the positive quadrant</span>, uniformly radially distributed, and we track them for <span style="color: #00a5a5">1M turns</span>.
            </small>
          </script>
        </section>

        <section data-markdown>
          <script type="text/template">
            ### How do we <span style="color: #00a5a5">optimize</span> the DA?

            <small>

            Short answer: <span style="color: orange;">brute force</span>.

            <img src="assets/oct_scan_cropped.png" alt="tune-scan" width="400"/>

            Very unelegant... but usual optimization algorithms are not efficient for this problem, since computing the DA gradient is expensive and it's easier to massively parallelize.

            </small>
          </script>
        </section>
        <section data-markdown>
          <script type="text/template">
            ### How do we <span style="color: #00a5a5">optimize</span> the DA?

            <small>

            But <span style="color: green;">not a lost cause</span>. Probably the computational load could be reduced by a large factor using some smart DA precursors.

            <span style="color: #00a5a5">Other consideration</span>: physicists like to have the full picture of the DA landscape, reducing the interest for optimizing the parameter space exploration.

            &nbsp;
            And finally, we already decrease (a bit) the computational load by:
            - trying to minize the size of the regions to scan (e.g. half tune scan)
            - adapting the range of amplitude we track (<span style="color: orange">tricky</span>)

            </small>
          </script>
        </section>

        <section data-markdown>
          <script type="text/template">
            ### <span style="color: #00a5a5">Why</span>  are tools needed for the DA?

            <small>

            Many plots like this one must be produced regularly, sometimes with hard deadlines:

            <img src="assets/tune_scan.png" alt="tune-scan" width="200"/>

            ... But history has shown that problems almost always arise:

            - <span style="color: orange">problem</span> with the Mad-X optics
            - <span style="color: orange">problem</span> with the parametrization of the scan
            - <span style="color: orange">problem</span> with the study code
            - <span style="color: orange">problem</span> with Python dependencies or Xsuite upgrade
            - <span style="color: orange">problem</span> with HTCondor
            - <span style="color: orange">problem</span> with the postprocessing
            - <span style="color: orange">problem</span> with the plotting

            </small>
          </script>
        </section>

        <section data-markdown>
          <script type="text/template">
            ### <span style="color: #00a5a5">Why</span> are tools needed for the DA?

            <small>

            <img src="assets/tune_scan.png" alt="tune-scan" width="300"/>

            Yet the scan itself can take <span style="color: orange">a couple of days to run</span> (sometimes more), and problems often reveal themselves afterwards... Meaning that one has to start all over again.

            To anticipate and avoid these stressful situations, we need to have a <span style="color: #00a5a5">robust</span> and <span style="color: #00a5a5">reproducible</span> workflow.

            In addition, not much documentation available for the uninitiated... and I'm leaving soon.

            </small>
          </script>
        </section>

        <section data-markdown>
          <script type="text/template">
            ### <span style="color: #00a5a5">What</span> was available so far

            <small>

            For the past 2 years, to ease the process of DA studies, I have adapted some legacy code to develop and maintain [template DA studies](https://github.com/xsuite/DA_study_template), available on the Xsuite repository.

            These templates have been very useful so far, and are stable, but they are not perfect, as:

            - they are <span style="color: orange">hard to maintain</span>, since we have one template for each LHC version, with a lot of code redundancy across templates.
            - they are <span style="color: orange">not so user-friendly</span>, since they must be modified extensively when doing a new study.
            - they incoporate <span style="color: orange">redundancies in the parameter declaration</span>, leading to potential inconsistencies.
            - they are <span style="color: orange">hard to adapt</span> for multigenerational scans (I'll come back to this).
            - they are <span style="color: orange">tedious to work with</span> since several separate scripts must be run in a specific order, updating each of them manually.
            - they are <span style="color: orange">not easily adaptable to build, configure and track a single collider</span>. Only scans.
            - they are <span style="color: orange">not standardized</span> (open scripts), leading to inconsistencies propagating across the different scripts.
            - they are <span style="color: orange">not so easy to setup</span> (not pip-installable) since they are open scripts.

            </small>
          </script>
        </section>

        <section data-markdown>
          <script type="text/template">
            ### <span style="color: #00a5a5">What</span> was available so far

            <small>

            Other issues (which I could have solved with the templates but did not because of time):
            - templates <span style="color: orange">do not incorporate tools for plotting</span>.
            - templates have sometimes <span style="color: orange">unexpected compatibility issues with Xsuite</span> (or other dependencies), since no Continuous Integration (CI) pipeline is set up.

            &nbsp;

            The package that I'm going to present today, [study-DA](https://colasdroin.github.io/study-DA/index.html), aims at solving all these issues.

            - It is <span style="color: #00a5a5">more user-friendly</span> and <span style="color: #00a5a5">easily flexible</span> while being more standardized.
            - It will also be <span style="color: #00a5a5">more robust</span>, since it will be tested with a CI pipeline.
            - It is more <span style="color: #00a5a5">easily maintainable</span>, since all the common code is now centralized in a given set of classes and functions.
            - It <span style="color: #00a5a5">doesn't change the philosophy of the previous templates</span>, and can be thought of an additional meta-layer to the templates to ease the overall workflow.

            </small>
          </script>
        </section>

        <section data-markdown data-background="#eeeeee">
          <script type="text/template">
            ### Introducing <span style="color: #00a5a5">study-DA</span>
          </script>
        </section>

        <section data-markdown>
          <script type="text/template">
            ### What is <span style="color: #00a5a5">study-DA</span>

            <small>

              study-DA comprises everything needed to do a full DA study, through 4 main classes:

              - <span style="color: #00a5a5">Generation</span>: Provides functions to generate, from template scripts and a configuration file, the dynamics aperture study as a multi-generational tree representing the various layers of the corresponding parametric scan.

              - <span style="color: #00a5a5">Submission</span>: Allows seamless submission of the generated study locally and/or to computing clusters (mainly HTCondor), and the automatic retrieval of the results.

              - <span style="color: #00a5a5">Postprocessing</span>: Provides functions to postprocess the raw results (usually `.parquet` files from tracking) and aggregate them into a Pandas `DataFrame`.

              - <span style="color: #00a5a5">Plotting</span>: Provides functions to visualize the postprocessed results as 2D and 3D heatmaps.

              It also includes template scripts for "usual" DA studies, configurations files for HL-LHC v1.6 and v1.3, and run III (including ions).

              Finally, it includes code for building and configuring a collider, and tracking particles.

            </small>
          </script>
        </section>

        <section data-markdown>
          <script type="text/template">
            ### Understanding the workflow

            <small>
            The workflow of study DA is usually the following:

            1. Create/adapt a <span style="color: #00a5a5">configuration file for the parameters</span> of your study (optics, knobs, etc.).

            2. Create your studies as a <span style="color: #00a5a5">set of Python scripts</span>: A, B, C... such that B depends on the output of A, C depends on the output of B (and potentially C), etc. All of these scripts use the <span style="color: #00a5a5">same configuration file</span>.

            3. Create a <span style="color: #00a5a5">configuration file for the scan</span> for the parameters, for each script (i.e. generation).

            4. <span style="color: #00a5a5">Generate your study as a tree</span>, scanning the adequate parameters at each generation, and using the corresponding scripts.

            5. <span style="color: #00a5a5">Submit</span> your scripts as jobs (locally or to the cluster).

            6. <span style="color: #00a5a5">Aggregate the results</span> of the scripts.

            7. Do the analysis and <span style="color: #00a5a5">plot</span>.

            Let's consider practical examples to better understand.
            
            </small>
          </script>
        </section>

        <section data-markdown data-background="#eeeeee">
          <script type="text/template">
            ### A small <span style="color: #00a5a5">tutorial</span>
          </script>
        </section>

        <section data-markdown data-auto-animate>
          <script type="text/template">
            ### Tutorial: <span style="color: #00a5a5">generation</span>

            <small>
              
              Configuration file for the study parameters:

              <pre style="width: 100%;"
              data-id="code-animation"
            ><code class="hljs yaml" data-trim style="max-height: 38vh;"><script type="text/template">
            
            a_random_nest:
              x: -1
            y: -2
            another_random_nest:
              and_another:
                z: -3
  
            </script></code></pre>

            </small>
          </script>
        </section>


        <section data-markdown data-auto-animate>
          <script type="text/template">
            ### Tutorial: <span style="color: #00a5a5">generation</span>

            <small>
              
              Script for generation 1:

              <pre style="width: 100%;"
              data-id="code-animation"
            ><code class="hljs python" data-trim data-line-numbers="|23-27|33-34|44-55" style="max-height: 38vh;"><script type="text/template">

              # ==================================================================================================
              # --- Imports
              # ==================================================================================================
              
              # Import standard library modules
              import logging
              import os
              
              # Import third-party modules
              # Import user-defined modules
              from study_da.utils import (
                  load_dic_from_path,
                  set_item_in_dic,
                  write_dic_to_path,
              )
              
              # Set up the logger here if needed
              
              
              # ==================================================================================================
              # --- Script functions
              # ==================================================================================================
              def add(configuration):
                  x = float(configuration["a_random_nest"]["x"])
                  z = float(configuration["another_random_nest"]["and_another"]["z"])
                  configuration["result"] = {"x_plus_z": x + z}
                  return configuration
              
              
              # ==================================================================================================
              # --- Parameters definition
              # ==================================================================================================
              dict_mutated_parameters = {{parameters}}
              path_configuration = "{{main_configuration}}"
              
              # ==================================================================================================
              # --- Script for execution
              # ==================================================================================================
              
              if __name__ == "__main__":
                  logging.info("Starting custom script")
              
                  # Load full configuration
                  full_configuration, ryaml = load_dic_from_path(path_configuration)
              
                  # Mutate parameters in configuration
                  for key, value in dict_mutated_parameters.items():
                      set_item_in_dic(full_configuration, key, value)
              
                  # Add x and z and write to configuration
                  full_configuration = add(full_configuration)
              
                  # Dump configuration
                  name_configuration = os.path.basename(path_configuration)
                  write_dic_to_path(full_configuration, name_configuration, ryaml)
              
                  logging.info("Script finished")
            </script></code></pre>

            </small>
          </script>
        </section>

        <section data-markdown data-auto-animate>
          <script type="text/template">
            ### Tutorial: <span style="color: #00a5a5">generation</span>

            <small>
              
              Script for generation 2:

              <pre style="width: 100%;"
              data-id="code-animation"
            ><code class="hljs python" data-trim data-line-numbers="|23-29|35-36|45-57" style="max-height: 38vh;"><script type="text/template">

              # ==================================================================================================
              # --- Imports
              # ==================================================================================================
              
              # Import standard library modules
              import logging
              import os
              
              # Import third-party modules
              # Import user-defined modules
              from study_da.utils import (
                  load_dic_from_path,
                  set_item_in_dic,
                  write_dic_to_path,
              )
              
              # Set up the logger here if needed
              
              
              # ==================================================================================================
              # --- Script functions
              # ==================================================================================================
              def multiply_and_dump(configuration):
                  y = float(configuration["y"])
                  x_plus_z = float(configuration["result"]["x_plus_z"])
              
                  # Dump result to txt file
                  with open("result.txt", "w") as f:
                      f.write(str(x_plus_z * y))
              
              
              # ==================================================================================================
              # --- Parameters definition
              # ==================================================================================================
              dict_mutated_parameters = {{parameters}}
              path_configuration = "{{main_configuration}}"
              
              # ==================================================================================================
              # --- Script for execution
              # ==================================================================================================
              
              if __name__ == "__main__":
                  logging.info("Starting custom script")
              
                  # Load full configuration
                  full_configuration, ryaml = load_dic_from_path(path_configuration)
              
                  # Mutate parameters in configuration
                  for key, value in dict_mutated_parameters.items():
                      set_item_in_dic(full_configuration, key, value)
              
                  # Add x and z and write to configuration
                  multiply_and_dump(full_configuration)
              
                  # Dump configuration
                  name_configuration = os.path.basename(path_configuration)
                  write_dic_to_path(full_configuration, name_configuration, ryaml)
              
                  logging.info("Script finished")
            </script></code></pre>

            </small>
          </script>
        </section>


        <section data-markdown data-auto-animate>
          <script type="text/template">
            ### Tutorial: <span style="color: #00a5a5">generation</span>

            <small>
              
              Configuration file for the scan:

              <pre style="width: 100%;"
              data-id="code-animation"
            ><code class="hljs yaml" data-trim style="max-height: 38vh;"><script type="text/template">
            


              name: example_dummy

              # List all useful files that will be used by executable in generations below
              # These files are placed at the root of the study
              dependencies:
                main_configuration: custom_files/config_dummy.yaml
              
              structure:
                # First generation is always at the root of the study
                # such that config_dummy.yaml is accessible as ../config_dummy.yaml
                generation_1:
                  executable: custom_files/generation_1_dummy.py
                  scans:
                    x:
                      # Values taken by x using a list
                      list: [1, 2]
              
                # Second generation depends on the config from the first generation
                generation_2:
                  executable: custom_files/generation_2_dummy.py
                  scans:
                    y:
                      # Values taken by y using a linspace
                      linspace: [1, 100, 3]

            </script></code></pre>

            </small>
          </script>
        </section>


        <section data-markdown data-auto-animate>
          <script type="text/template">
            ### Tutorial: <span style="color: #00a5a5">generation</span>

            <small>
              
              You can now generate the study with a one-liner (almost):

              <pre style="width: 100%;"
              data-id="code-animation"
            ><code class="hljs python" data-trim style="max-height: 38vh;"><script type="text/template">

              from study_da import create
              create(path_config_scan="config_scan.yaml")

            </script></code></pre>


            </small>

          </script>
        </section>

        <section data-markdown data-auto-animate>
          <script type="text/template">
            ### Tutorial: <span style="color: #00a5a5">generation</span>

            <small>
              
              If you check the folder in which you ran the command, you should see the following:

              <pre style="width: 100%;"
              data-id="code-animation"
            ><code class="hljs bash" data-trim style="max-height: 38vh;"><script type="text/template">

              📁 example_dummy/
              ├─╴📁 x_1/
              │   ├── 📁 y_1.0/
              │   ├── 📁 y_50.5/
              │   ├── 📁 y_100.0/
              │   │   └── 📄 generation_2.py
              │   └── 📄 generation_1.py
              ├─╴📁 x_2/
              ├─ 📄 tree.yaml
              └─ 📄 config_dummy.yaml

            </script></code></pre>
          </small>

        </script>
      </section>

        <section data-markdown data-auto-animate>
              <script type="text/template">
                ### Tutorial: <span style="color: #00a5a5">generation</span>
    
                <small>
                  
                  Which is basically what is contained in the tree file:
    
                  <pre style="width: 100%;"
                  data-id="code-animation"
                ><code class="hljs yaml" data-trim style="max-height: 38vh;"><script type="text/template">
    
                  x_1:
                  generation_1:
                    file: example_dummy/x_1/generation_1.py
                  y_1.0:
                    generation_2:
                      file: example_dummy/x_1/y_1.0/generation_2.py
                  y_50.5:
                    generation_2:
                      file: example_dummy/x_1/y_50.5/generation_2.py
                  y_100.0:
                    generation_2:
                      file: example_dummy/x_1/y_100.0/generation_2.py
                x_2:
                  generation_1:
                    file: example_dummy/x_2/generation_1.py
                  y_1.0:
                    generation_2:
                      file: example_dummy/x_2/y_1.0/generation_2.py
                  y_50.5:
                    generation_2:
                      file: example_dummy/x_2/y_50.5/generation_2.py
                  y_100.0:
                    generation_2:
                      file: example_dummy/x_2/y_100.0/generation_2.py
                
    
                </script></code></pre>
            </small>
          </script>
        </section>

        <section data-markdown data-auto-animate>
          <script type="text/template">
            ### Tutorial: <span style="color: #00a5a5">generation</span>

            <small>
              
              And if we now look at the content of the example_dummy/x_1/generation_1.py file:

              <pre style="width: 100%;"
              data-id="code-animation"
            ><code class="hljs python" data-trim data-line-numbers="|33-36|" style="max-height: 38vh;"><script type="text/template">

              # ==================================================================================================
              # --- Imports
              # ==================================================================================================
              
              # Import standard library modules
              import logging
              import os
              
              # Import third-party modules
              # Import user-defined modules
              from study_da.utils import (
                  load_dic_from_path,
                  set_item_in_dic,
                  write_dic_to_path,
              )
              
              # Set up the logger here if needed
              
              
              # ==================================================================================================
              # --- Script functions
              # ==================================================================================================
              def add(configuration):
                  x = float(configuration["a_random_nest"]["x"])
                  z = float(configuration["another_random_nest"]["and_another"]["z"])
                  configuration["result"] = {"x_plus_z": x + z}
                  return configuration
              
              
              # ==================================================================================================
              # --- Parameters definition
              # ==================================================================================================
              dict_mutated_parameters = {
                  "x": 1,
              }
              path_configuration = "../config_dummy.yaml"
              
              # ==================================================================================================
              # --- Script for execution
              # ==================================================================================================
              
              if __name__ == "__main__":
                  logging.info("Starting custom script")
              
                  # Load full configuration
                  full_configuration, ryaml = load_dic_from_path(path_configuration)
              
                  # Mutate parameters in configuration
                  for key, value in dict_mutated_parameters.items():
                      set_item_in_dic(full_configuration, key, value)
              
                  # Add x and z and write to configuration
                  full_configuration = add(full_configuration)
              
                  # Dump configuration
                  name_configuration = os.path.basename(path_configuration)
                  write_dic_to_path(full_configuration, name_configuration, ryaml)
              
                  logging.info("Script finished")
              
            </script></code></pre>

            </small>
          </script>
        </section>


        <section data-markdown data-auto-animate>
          <script type="text/template">
            ### Tutorial: <span style="color: #00a5a5">submission</span>

            <small>
              
              Let's now complete our generating script to include the submission:

              <pre style="width: 100%;"
              data-id="code-animation"
            ><code class="hljs python" data-trim style="max-height: 38vh;"><script type="text/template">

              from study_da import create, submit
              path_tree, main_configuration_file = create(path_config_scan="config_scan.yaml", force_overwrite=False)
              submit(
                  path_tree=path_tree,
                  path_python_environment="/afs/cern.ch/work/u/user/private/study-DA/.venv",
                  name_config=main_configuration_file,
                  keep_submit_until_done=True,
                  wait_time=0.1,
              )

            </script></code></pre>


            </small>

          </script>
        </section>

        <section data-markdown data-auto-animate>
          <script type="text/template">
            ### Tutorial: <span style="color: #00a5a5">submission</span>

            <small>
              
              If we run this script, we should see the following:

              <pre style="width: 100%;"
              data-id="code-animation"
            ><code class="hljs bash" data-trim style="max-height: 38vh;"><script type="text/template">

              State of the jobs:
              ********************************
              Generation 1
              Jobs left to submit later: 0
              Jobs running or queuing: 0
              Jobs submitted now: 2
              Jobs finished: 0
              Jobs failed: 0
              Jobs on hold due to failed dependencies: 0
              ********************************
              ********************************
              Generation 2
              Jobs left to submit later: 6
              Jobs running or queuing: 0
              Jobs submitted now: 0
              Jobs finished: 0
              Jobs failed: 0
              Jobs on hold due to failed dependencies: 0
              ********************************

            </script></code></pre>


            </small>

          </script>
        </section>

        <section data-markdown data-auto-animate>
          <script type="text/template">
            ### Tutorial: <span style="color: #00a5a5">submission</span>

            <small>
              
              Behind the hood, study-DA has been launching this type of run files:

              <pre style="width: 100%;"
              data-id="code-animation"
            ><code class="hljs bash" data-trim style="max-height: 38vh;"><script type="text/template">

              #!/bin/bash
              # Load the environment
              source /afs/cern.ch/work/c/cdroin/private/study-DA/.venv/bin/activate
              
              # Move into the job folder
              cd /afs/cern.ch/work/c/cdroin/.../example_dummy/x_1
              
              # Run the job and tag
              python generation_1.py > output_python.txt 2> error_python.txt
              
              # Ensure job run was successful and tag as finished, or as failed otherwise
              if [ $? -eq 0 ]; then
                  touch /afs/cern.ch/work/c/cdroin/.../example_dummy/x_1/.finished
              else
                  touch /afs/cern.ch/work/c/cdroin/.../example_dummy/x_1/.failed
              fi
              
              # Store abs path as a variable in case it's needed for additional commands
              path_job=$(pwd)
              # Optional user defined command to run

            </script></code></pre>
            </small>
          </script>
        </section>

        <section data-markdown data-auto-animate>
          <script type="text/template">
            ### Tutorial: <span style="color: #00a5a5">generation</span>

            <small>
              
              If we now recheck the tree, we should see that the jobs are fully configured and have started running:

              <pre style="width: 100%;"
              data-id="code-animation"
            ><code class="hljs yaml" data-trim style="max-height: 38vh;"><script type="text/template">

              x_1:
              generation_1:
                file: example_dummy/x_1/generation_1.py
                context: cpu
                submission_type: local
                htc_flavor: espresso
                status: finished
                path_run: 
                  /afs/cern.ch/work/c/cdroin/private/study-DA/examples/in_docs/dummy_custom_template/example_dummy/x_1/run.sh
              y_1.0:
                generation_2:
                  file: example_dummy/x_1/y_1.0/generation_2.py
                  context: cpu
                  submission_type: local
                  htc_flavor: espresso
                  status: to_submit
                  path_run: 
                    /afs/cern.ch/work/c/cdroin/private/study-DA/examples/in_docs/dummy_custom_template/example_dummy/x_1/y_1.0/run.sh
              y_50.5:
                generation_2:
                  file: example_dummy/x_1/y_50.5/generation_2.py
                  context: cpu
                  submission_type: local
                  htc_flavor: espresso
                  status: to_submit
                  path_run: 
                    /afs/cern.ch/work/c/cdroin/private/study-DA/examples/in_docs/dummy_custom_template/example_dummy/x_1/y_50.5/run.sh
              y_100.0:
                generation_2:
                  file: example_dummy/x_1/y_100.0/generation_2.py
                  context: cpu
                  submission_type: local
                  htc_flavor: espresso
                  status: to_submit
                  path_run: 
                    /afs/cern.ch/work/c/cdroin/private/study-DA/examples/in_docs/dummy_custom_template/example_dummy/x_1/y_100.0/run.sh
            x_2:
              generation_1:
                file: example_dummy/x_2/generation_1.py
                context: cpu
                submission_type: local
                htc_flavor: espresso
                status: finished
                path_run: 
                  /afs/cern.ch/work/c/cdroin/private/study-DA/examples/in_docs/dummy_custom_template/example_dummy/x_2/run.sh
              y_1.0:
                generation_2:
                  file: example_dummy/x_2/y_1.0/generation_2.py
                  context: cpu
                  submission_type: local
                  htc_flavor: espresso
                  status: to_submit
                  path_run: 
                    /afs/cern.ch/work/c/cdroin/private/study-DA/examples/in_docs/dummy_custom_template/example_dummy/x_2/y_1.0/run.sh
              y_50.5:
                generation_2:
                  file: example_dummy/x_2/y_50.5/generation_2.py
                  context: cpu
                  submission_type: local
                  htc_flavor: espresso
                  status: to_submit
                  path_run: 
                    /afs/cern.ch/work/c/cdroin/private/study-DA/examples/in_docs/dummy_custom_template/example_dummy/x_2/y_50.5/run.sh
              y_100.0:
                generation_2:
                  file: example_dummy/x_2/y_100.0/generation_2.py
                  context: cpu
                  submission_type: local
                  htc_flavor: espresso
                  status: to_submit
                  path_run: 
                    /afs/cern.ch/work/c/cdroin/private/study-DA/examples/in_docs/dummy_custom_template/example_dummy/x_2/y_100.0/run.sh
            python_environment: 
              /afs/cern.ch/work/c/cdroin/private/study-DA/examples/in_docs/dummy_custom_template/bin/activate
            absolute_path: 
              /afs/cern.ch/work/c/cdroin/private/study-DA/examples/in_docs/dummy_custom_template
            status: to_finish
            configured: true
            
            </script></code></pre>
        </small>
      </script>
    </section>


    <section data-markdown data-auto-animate>
      <script type="text/template">
        ### Tutorial: <span style="color: #00a5a5">submission</span>

        <small>
          
          Let's now try to do the same submission with Docker on HTCondor (preconfiguring to gain time):

          <pre style="width: 100%;"
          data-id="code-animation"
        ><code class="hljs python" data-trim style="max-height: 38vh;"><script type="text/template">

          from study_da import create, submit

          # Generate the study in the local directory
          path_tree, main_configuration_file = create(
              path_config_scan="config_scan.yaml", force_overwrite=False
          )
          
          path_python_environment_container = "/usr/local/DA_study/miniforge_docker"
          path_container_image = (
              "/cvmfs/unpacked.cern.ch/gitlab-registry.cern.ch/cdroin/da-study-docker:0b46f2bb"
          )
          
          # Dic copy_back_per_gen (only for HTC)
          dic_copy_back_per_gen = {
              2: {"txt": True},
          }
          
          # Preconfigure submission to HTC
          dic_config_jobs = {
              "generation_1" + ".py": {
                  "context": "cpu",
                  "submission_type": "htc_docker",
                  "htc_flavor": "espresso",
              },
              "generation_2" + ".py": {
                  "context": "cpu",
                  "submission_type": "htc_docker",
                  "htc_flavor": "espresso",
              },
          }
          
          # Submit the study
          submit(
              path_tree=path_tree,
              name_config=main_configuration_file,
              path_python_environment_container=path_python_environment_container,
              path_container_image=path_container_image,
              dic_copy_back_per_gen=dic_copy_back_per_gen,
              dic_config_jobs=dic_config_jobs,
              keep_submit_until_done=True,
              wait_time=2,
          )

        </script></code></pre>
        </small>
      </script>
    </section>

    <section data-markdown data-auto-animate>
      <script type="text/template">
        ### Tutorial: <span style="color: #00a5a5">submission</span>

        <small>
          
          Basically everything is the same as before, except that the generated run file is a bit more complicated:

          <pre style="width: 100%;"
          data-id="code-animation"
        ><code class="hljs bash" data-trim style="max-height: 38vh;"><script type="text/template">

          #!/bin/bash
          # Load the environment
          source /usr/local/DA_study/miniforge_docker/bin/activate
          
          # Copy config in (what will be) the level above
          cp -f /afs/cern.ch/work/c/cdroin/...example_dummy/x_2/y_1.0/../config_dummy.yaml .
          
          # Create local directory on node and cd into it
          mkdir y_1.0
          cd y_1.0
          
          # Mutate the paths in config to be absolute
          
          # Run the job and tag
          python /afs/cern.ch/work/c/cdroin/.../example_dummy/x_2/y_1.0/generation_2.py > output_python.txt 2> error_python.txt
          
          
          # Ensure job run was successful and tag as finished, or as failed otherwise
          if [ $? -eq 0 ]; then
              touch /afs/cern.ch/work/c/cdroin/.../example_dummy/x_2/y_1.0/.finished
          else
              touch /afs/cern.ch/work/c/cdroin/.../example_dummy/x_2/y_1.0/.failed
          fi
          
          # Delete the config file from the above directory, otherwise it will be copied back and overwrite the new config
          rm ../config_dummy.yaml
          # Copy back output, including the new config
          cp -f *.parquet *.yaml *.txt /afs/cern.ch/work/c/cdroin/.../example_dummy/x_2/y_1.0
          
          # Store abs path as a variable in case it's needed for additional commands
          path_job=/afs/cern.ch/work/c/cdroin/.../example_dummy/x_2/y_1.0
          
          # Optional user defined command to run

        </script></code></pre>
        </small>
      </script>
    </section>


    <section data-markdown data-background="#eeeeee">
      <script type="text/template">
        ### A practical <span style="color: #00a5a5">example</span> of DA study
      </script>
    </section>

    <section data-markdown data-auto-animate>
      <script type="text/template">
        ### A practical <span style="color: #00a5a5">example</span>

        <small>
          
          Configuration file for the study parameters is the same as usual (almost nothing new here):

          <pre style="width: 100%;"
          data-id="code-animation"
        ><code class="hljs yaml" data-trim data-line-numbers="|1-7|70-71, 76|247-248, 252|255" style="max-height: 38vh;"><script type="text/template">
        
          config_particles:
          r_min: 4.0
          r_max: 8.0
          n_r: 256
          n_angles: 5
          n_split: 5
          path_distribution_folder_output: particles
        
        config_mad:
          # Links to be made for tools and scripts
          links:
            acc-models-lhc: /afs/cern.ch/eng/lhc/optics/runIII
        
          # Optics file
          optics_file: acc-models-lhc/RunIII_dev/Proton_2024/opticsfile.37 #
        
          # Beam parameters
          beam_config:
            lhcb1:
              beam_energy_tot: 6800 # [GeV]
            lhcb2:
              beam_energy_tot: 6800 # [GeV]
        
          # Ions being simulated
          ions: false
        
          # Enable machine imperfections
          enable_imperfections: false
        
          # Enable knob synthesis (for coupling correction, if no imperfections)
          enable_knob_synthesis: true
        
          # Rename the coupling knobs to avoid conflict between b1 and b2
          # (for hllhc using old fortran code to generate the knobs)
          rename_coupling_knobs: true
        
          # Optics version, for choice of correction algorithms
          # (ver_lhc_run or ver_hllhc_optics)
          ver_hllhc_optics:
          ver_lhc_run: 3.0
        
          # Parameters for machine imperfections
          pars_for_imperfections:
            par_myseed: 1
            par_correct_for_D2: 0
            par_correct_for_MCBX: 0
            par_on_errors_LHC: 1
            par_off_errors_Q4_inIP15: 0
            par_off_errors_Q5_inIP15: 0
            par_on_errors_MBH: 1
            par_on_errors_Q4: 1
            par_on_errors_D2: 1
            par_on_errors_D1: 1
            par_on_errors_IT: 1
            par_on_errors_MCBRD: 0
            par_on_errors_MCBXF: 0
            par_on_errors_NLC: 0
            par_write_errortable: 1
        
          phasing:
            # RF voltage and phases
            vrf400: 12.0 # [MV]
            lagrf400.b1: 0.5 # [rad]
            lagrf400.b2: 0. # [rad]
        
          # To make some specifics checks
          sanity_checks: true
        
          # Path of the collider file to be saved (usually at the end of the first generation)
          path_collider_file_for_configuration_as_output: collider_file_for_configuration.json
          compress: true # will compress the collider file, filename will end with .zip
        
        # Configuration for tuning of the collider
        config_collider:
          # Even though the file doesn't end with .zip, scrip will first try to load it as a zip file
          path_collider_file_for_configuration_as_input: ../collider_file_for_configuration.json
          config_knobs_and_tuning:
            knob_settings:
              # Exp. configuration in IR1, IR2, IR5 and IR8***
              on_x1: -145.000
              on_sep1: 0.0 #-0.550
              phi_IR1: 180.000
        
              on_x2h: 0.000
              on_sep2h: 1.0 # 1.000
              on_x2v: 200.000
              on_sep2v: 0.000
              phi_IR2: 90.000
        
              on_x5: 145.000
              on_sep5: 0.0 # 0.550
              phi_IR5: 90.000
        
              on_x8h: 0.000
              on_sep8h: -0.01 #-1.000
              on_x8v: 200.000
              on_sep8v: 0.000
              phi_IR8: 180.000
        
              # Spurious dispersion correction
              on_disp: 1.000
        
              # Magnets of the experiments
              on_alice_normalized: 1
              on_lhcb_normalized: 1
              on_sol_atlas: 0
              on_sol_cms: 0
              on_sol_alice: 0
        
              # Octupoles
              i_oct_b1: 300. # [A]
              i_oct_b2: 300. # [A]
        
            # Tunes and chromaticities
            qx:
              lhcb1: 62.31
              lhcb2: 62.31
            qy:
              lhcb1: 60.32
              lhcb2: 60.32
            dqx:
              lhcb1: 15
              lhcb2: 15
            dqy:
              lhcb1: 15
              lhcb2: 15
        
            # Linear coupling
            delta_cmr: 0.001
            delta_cmi: 0.0
        
            knob_names:
              lhcb1:
                q_knob_1: dqx.b1_sq
                q_knob_2: dqy.b1_sq
                dq_knob_1: dqpx.b1_sq
                dq_knob_2: dqpy.b1_sq
                c_minus_knob_1: c_minus_re_b1
                c_minus_knob_2: c_minus_im_b1
              lhcb2:
                q_knob_1: dqx.b2_sq
                q_knob_2: dqy.b2_sq
                dq_knob_1: dqpx.b2_sq
                dq_knob_2: dqpy.b2_sq
                c_minus_knob_1: c_minus_re_b2
                c_minus_knob_2: c_minus_im_b2
        
          config_beambeam:
            skip_beambeam: false
            bunch_spacing_buckets: 10
            num_slices_head_on: 11
            num_long_range_encounters_per_side:
              ip1: 25
              ip2: 20
              ip5: 25
              ip8: 20
            sigma_z: 0.09
            num_particles_per_bunch: 1.15e11
            nemitt_x: 2.2e-6
            nemitt_y: 2.2e-6
            mask_with_filling_pattern:
              # If not already existing in the study-da package, pattern must have an absolute path or be
              # added as a dependency for the run file
              pattern_fname: 8b4e_1972b_1960_1178_1886_224bpi_12inj_800ns_bs200ns.json
              i_bunch_b1:      # If not specified, the bunch with the worst schedule is chosen
              i_bunch_b2:      # Same. A value for i_bunch_b1 and i_bunch_b2 must be specified if pattern_fname is specified
            cross_section: 81e-27
        
          config_lumi_leveling_ip1_5:
            skip_leveling: false
            luminosity: 2.0e+34
            num_colliding_bunches:      # This will be set automatically according to the filling scheme
            vary:
            - num_particles_per_bunch
            constraints:
              max_intensity: 1.8e11
              max_PU: 70
        
          skip_leveling: false
          config_lumi_leveling:
            ip2:
              separation_in_sigmas: 5
              plane: x
              impose_separation_orthogonal_to_crossing: false
              knobs:
              - on_sep2h
              - on_sep2v
              bump_range:
                lhcb1:
                - e.ds.l2.b1
                - s.ds.r2.b1
                lhcb2:
                - s.ds.r2.b2
                - e.ds.l2.b2
              preserve_angles_at_ip: true
              preserve_bump_closure: true
              corrector_knob_names:
                # to preserve angles at ip
              - corr_co_acbyvs4.l2b1
              - corr_co_acbyhs4.l2b1
              - corr_co_acbyvs4.r2b2
              - corr_co_acbyhs4.r2b2
                # to close the bumps
              - corr_co_acbyvs4.l2b2
              - corr_co_acbyhs4.l2b2
              - corr_co_acbyvs4.r2b1
              - corr_co_acbyhs4.r2b1
              - corr_co_acbyhs5.l2b2
              - corr_co_acbyvs5.l2b2
              - corr_co_acbchs5.r2b1
              - corr_co_acbcvs5.r2b1
        
            ip8:
              luminosity: 2.0e+33
              num_colliding_bunches:      # This will be set automatically according to the filling scheme
              impose_separation_orthogonal_to_crossing: true
              knobs:
              - on_sep8h
              - on_sep8v
              bump_range:
                lhcb1:
                - e.ds.l8.b1
                - s.ds.r8.b1
                lhcb2:
                - s.ds.r8.b2
                - e.ds.l8.b2
              preserve_angles_at_ip: true
              preserve_bump_closure: true
              corrector_knob_names:
                # to preserve angles at ip
              - corr_co_acbyvs4.l8b1
              - corr_co_acbyhs4.l8b1
              - corr_co_acbyvs4.r8b2
              - corr_co_acbyhs4.r8b2
                # to close the bumps
              - corr_co_acbyvs4.l8b2
              - corr_co_acbyhs4.l8b2
              - corr_co_acbyvs4.r8b1
              - corr_co_acbyhs4.r8b1
              - corr_co_acbcvs5.l8b2
              - corr_co_acbchs5.l8b2
              - corr_co_acbyvs5.r8b1
              - corr_co_acbyhs5.r8b1
        
          # Save collider or not (usually at the end of the collider tuning)
          save_output_collider: false
          path_collider_file_for_tracking_as_output: collider_file_for_tracking.json
          compress: true # will compress the collider file, filename will end with .zip
        
        config_simulation:
          # Collider file to load for the tracking
          path_collider_file_for_tracking_as_input: ../collider_file_for_tracking.json
        
          # Distribution in the normalized xy space
          path_distribution_folder_input: ../particles
          distribution_file: 00.parquet
        
          # Output particle file
          path_distribution_file_output: output_particles.parquet
        
          # Initial off-momentum
          delta_max: 27.e-5
        
          # Tracking
          n_turns: 1000000 # number of turns to track
        
          # Beam to track
          beam: lhcb1 #lhcb1 or lhcb2
        
          # Context for the simulation
          context: cpu   # 'cupy' # opencl
        
          # Device number for GPU simulation
          device_number: # 0

        </script></code></pre>

        </small>
      </script>
    </section>

    <section data-markdown data-auto-animate>
      <script type="text/template">
        ### Tutorial: <span style="color: #00a5a5">generation</span>

        <small>
          
          Template scripts for a usual 2-generational study are predefined in the package (the user can modify them if needed). Here's what <span style="color: #00a5a5">generation 1</span> looks like:

          <pre style="width: 100%;"
          data-id="code-animation"
        ><code class="hljs python" data-trim data-line-numbers="|27-35|38-55|61-62|69-88" style="max-height: 38vh;"><script type="text/template">

          """This is a template script for generation 1 of simulation study, in which ones generates a
          particle distribution and a collider from a MAD-X model."""
          
          # ==================================================================================================
          # --- Imports
          # ==================================================================================================
          
          # Import standard library modules
          import logging
          import os
          
          # Import third-party modules
          # Import user-defined modules
          from study_da.generate import MadCollider, ParticlesDistribution
          from study_da.utils import (
              load_dic_from_path,
              set_item_in_dic,
              write_dic_to_path,
          )
          
          # Set up the logger here if needed
          
          
          # ==================================================================================================
          # --- Script functions
          # ==================================================================================================
          def build_distribution(config_particles):
              # Build object for generating particle distribution
              distr = ParticlesDistribution(config_particles)
          
              # Build particle distribution
              particle_list = distr.return_distribution_as_list()
          
              # Write particle distribution to file
              distr.write_particle_distribution_to_disk(particle_list)
          
          
          def build_collider(config_mad):
              # Build object for generating collider from mad
              mc = MadCollider(config_mad)
          
              # Build mad model
              mad_b1b2, mad_b4 = mc.prepare_mad_collider()
          
              # Build collider from mad model
              collider = mc.build_collider(mad_b1b2, mad_b4)
          
              # Twiss to ensure everything is ok
              mc.activate_RF_and_twiss(collider)
          
              # Clean temporary files
              mc.clean_temporary_files()
          
              # Save collider to json
              mc.write_collider_to_disk(collider)
          
          
          # ==================================================================================================
          # --- Parameters definition
          # ==================================================================================================
          dict_mutated_parameters = {{parameters}}
          path_configuration = "{{main_configuration}}"
          
          # ==================================================================================================
          # --- Script for execution
          # ==================================================================================================
          
          if __name__ == "__main__":
              logging.info("Starting script to build particle distribution and collider")
          
              # Load full configuration
              full_configuration, ryaml = load_dic_from_path(path_configuration)
          
              # Mutate parameters in configuration
              for key, value in dict_mutated_parameters.items():
                  set_item_in_dic(full_configuration, key, value)
          
              # Dump configuration
              name_configuration = os.path.basename(path_configuration)
              write_dic_to_path(full_configuration, name_configuration, ryaml)
          
              # Build and save particle distribution
              build_distribution(full_configuration["config_particles"])
          
              # Build and save collider
              build_collider(full_configuration["config_mad"])
          
              logging.info("Script finished")
        </script></code></pre>

        </small>
      </script>
    </section>

    <section data-markdown data-auto-animate>
      <script type="text/template">
        ### Tutorial: <span style="color: #00a5a5">generation</span>

        <small>
          
          Here's what the default script for <span style="color: #00a5a5">generation 2</span> looks like:

          <pre style="width: 100%;"
          data-id="code-animation"
        ><code class="hljs python" data-trim data-line-numbers="|32-106|109-146|159-160|167-189" style="max-height: 38vh;"><script type="text/template">

          """This is a template script for generation 2 of simulation study, in which ones configures a collider
          and tracks a given particle distribution."""
          
          # ==================================================================================================
          # --- Imports
          # ==================================================================================================
          
          # Import standard library modules
          import contextlib
          import logging
          import os
          import time
          
          # Import third-party modules
          import numpy as np
          import pandas as pd
          
          # Import user-defined modules
          from study_da.generate import XsuiteCollider, XsuiteTracking
          from study_da.utils import (
              load_dic_from_path,
              set_item_in_dic,
              write_dic_to_path,
          )
          
          # Set up the logger here if needed
          
          
          # ==================================================================================================
          # --- Script functions
          # ==================================================================================================
          def configure_collider(full_configuration):
              # Get configuration
              config_collider = full_configuration["config_collider"]
              ver_hllhc_optics = full_configuration["config_mad"]["ver_hllhc_optics"]
              ver_lhc_run = full_configuration["config_mad"]["ver_lhc_run"]
              ions = full_configuration["config_mad"]["ions"]
              collider_filepath = full_configuration["config_collider"][
                  "path_collider_file_for_configuration_as_input"
              ]
          
              # Build object for configuring collider
              xc = XsuiteCollider(config_collider, collider_filepath, ver_hllhc_optics, ver_lhc_run, ions)
          
              # Load collider
              collider = xc.load_collider()
          
              # Install beam-beam
              xc.install_beam_beam_wrapper(collider)
          
              # Build trackers
              # For now, start with CPU tracker due to a bug with Xsuite
              # Refer to issue https://github.com/xsuite/xsuite/issues/450
              collider.build_trackers()  # (_context=context)
          
              # Set knobs
              xc.set_knobs(collider)
          
              # Match tune and chromaticity
              xc.match_tune_and_chroma(collider, match_linear_coupling_to_zero=True)
          
              # Set filling scheme
              xc.set_filling_and_bunch_tracked(ask_worst_bunch=False)
          
              # Compute the number of collisions in the different IPs
              n_collisions_ip1_and_5, n_collisions_ip2, n_collisions_ip8 = xc.compute_collision_from_scheme()
          
              # Do the leveling if requested
              if "config_lumi_leveling" in config_collider and not config_collider["skip_leveling"]:
                  xc.level_ip1_5_by_bunch_intensity(collider, n_collisions_ip1_and_5)
                  xc.level_ip2_8_by_separation(n_collisions_ip2, n_collisions_ip8, collider)
              else:
                  logging.warning(
                      "No leveling is done as no configuration has been provided, or skip_leveling"
                      " is set to True."
                  )
          
              # Add linear coupling
              xc.add_linear_coupling(collider)
          
              # Rematch tune and chromaticity
              xc.match_tune_and_chroma(collider, match_linear_coupling_to_zero=False)
          
              # Assert that tune, chromaticity and linear coupling are correct one last time
              xc.assert_tune_chroma_coupling(collider)
          
              # Configure beam-beam if needed
              if not xc.config_beambeam["skip_beambeam"]:
                  xc.configure_beam_beam(collider)
          
              # Update configuration with luminosity now that bb is known
              l_n_collisions = [
                  n_collisions_ip1_and_5,
                  n_collisions_ip2,
                  n_collisions_ip1_and_5,
                  n_collisions_ip8,
              ]
              xc.record_final_luminosity(collider, l_n_collisions)
          
              # Save collider to json (flag to save or not is inside function)
              xc.write_collider_to_disk(collider, full_configuration)
          
              # Get fingerprint
              fingerprint = xc.return_fingerprint(collider)
          
              return collider, fingerprint
          
          
          def track_particles(full_configuration, collider, fingerprint):
              # Get emittances
              n_emitt_x = full_configuration["config_collider"]["config_beambeam"]["nemitt_x"]
              n_emitt_y = full_configuration["config_collider"]["config_beambeam"]["nemitt_y"]
              xst = XsuiteTracking(full_configuration["config_simulation"], n_emitt_x, n_emitt_y)
          
              # Prepare particle distribution
              particles, particle_id, l_amplitude, l_angle = xst.prepare_particle_distribution_for_tracking(
                  collider
              )
          
              # Track
              particles_dict = xst.track(collider, particles)
          
              # Convert particles to dataframe
              particles_df = pd.DataFrame(particles_dict)
          
              # ! Very important, otherwise the particles will be mixed in each subset
              # Sort by parent_particle_id
              particles_df = particles_df.sort_values("parent_particle_id")
          
              # Assign the old id to the sorted dataframe
              particles_df["particle_id"] = particle_id
          
              # Register the amplitude and angle in the dataframe
              particles_df["normalized amplitude in xy-plane"] = l_amplitude
              particles_df["angle in xy-plane [deg]"] = l_angle * 180 / np.pi
          
              # Add some metadata to the output for better interpretability
              particles_df.attrs["hash"] = hash(fingerprint)
              particles_df.attrs["fingerprint"] = fingerprint
              particles_df.attrs["configuration"] = full_configuration
              particles_df.attrs["date"] = time.strftime("%Y-%m-%d %H:%M:%S")
          
              # Save output
              particles_df.to_parquet(
                  full_configuration["config_simulation"]["path_distribution_file_output"]
              )
          
          
          def clean():
              # Remote the correction folder, and potential C files remaining
              with contextlib.suppress(Exception):
                  os.system("rm -rf correction")
                  os.system("rm -f *.cc")
          
          
          # ==================================================================================================
          # --- Parameters definition
          # ==================================================================================================
          dict_mutated_parameters = {{parameters}}
          path_configuration = "{{main_configuration}}"
          
          # ==================================================================================================
          # --- Script for execution
          # ==================================================================================================
          
          if __name__ == "__main__":
              logging.info("Starting script to configure collider and track")
          
              # Load full configuration
              full_configuration, ryaml = load_dic_from_path(path_configuration)
          
              # Mutate parameters in configuration
              for key, value in dict_mutated_parameters.items():
                  set_item_in_dic(full_configuration, key, value)
          
              # Configure collider
              collider, fingerprint = configure_collider(full_configuration)
          
              # Drop updated configuration
              name_configuration = os.path.basename(path_configuration)
              write_dic_to_path(full_configuration, name_configuration, ryaml)
          
              # Track particles and save to disk
              track_particles(full_configuration, collider, fingerprint)
          
              # Clean temporary files
              clean()
          
              logging.info("Script finished")
        </script></code></pre>

        </small>
      </script>
    </section>

    <section data-markdown data-auto-animate>
      <script type="text/template">
        ### Tutorial: <span style="color: #00a5a5">generation</span>

        <small>
          
          Since all the files I've shown before are pre-registered in the package, the only step that 
          the user actually needs to get involved with is the <span style="color: #00a5a5">configuration file</span> for the scan:

          <pre style="width: 100%;"
          data-id="code-animation"
        ><code class="hljs yaml" data-trim style="max-height: 38vh;"><script type="text/template">
        
          # ==================================================================================================
          # --- Structure of the study ---
          # ==================================================================================================
          name: example_dummy_scan
          
          # List all useful files that will be used by executable in generations below
          # These files are placed at the root of the study
          dependencies:
            main_configuration: config_runIII.yaml
          
          structure:
            # First generation is always at the root of the study
            # such that config_hllhc16.yaml is accessible as ../config_hllhc16.yaml
            generation_1:
              executable: generation_1.py
              common_parameters:
                # Needs to be redeclared as it's used for parallelization
                # And re-used ine the second generation
                n_split: 5
          
            # Second generation depends on the config from the first generation
            generation_2:
              executable: generation_2_level_by_nb.py
              scans:
                distribution_file:
                  # Number of paths is set by n_split in the main config
                  path_list: ["____.parquet", n_split]
                qx:
                  subvariables: [lhcb1, lhcb2]
                  linspace: [62.305, 62.315, 11]
                n_turns:
                  logspace: [2, 5, 20]

        </script></code></pre>

        </small>
      </script>
    </section>

        <section style="text-align: left" data-markdown>
          <script type="text/template">
            # THANK YOU

            <span style="color: #00a5a5">Questions?</span> <span style="color: white">Suggestions?</span> <span style="color: green">Comments?</span>
          </script>
        </section>
      </div>
    </div>

    <script src="dist/reveal.js"></script>
    <script src="plugin/zoom/zoom.js"></script>
    <script src="plugin/notes/notes.js"></script>
    <script src="plugin/search/search.js"></script>
    <script src="plugin/markdown/markdown.js"></script>
    <script src="plugin/highlight/highlight.js"></script>
    <script>
      // Also available as an ES module, see:
      // https://revealjs.com/initialization/
      Reveal.initialize({
        controls: true,
        progress: true,
        center: true,
        hash: true,
        slideNumber: true,
        margin: 0.04,
        width: 1100,
        height: 700,

        // Learn about plugins: https://revealjs.com/plugins/
        plugins: [
          RevealZoom,
          RevealNotes,
          RevealSearch,
          RevealMarkdown,
          RevealHighlight,
        ],
      });
    </script>
  </body>
</html>
